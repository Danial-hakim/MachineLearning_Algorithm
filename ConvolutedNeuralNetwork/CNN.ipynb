{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612b5373-1fa7-4dcf-abb4-ab925d33b58e",
   "metadata": {},
   "source": [
    "| Changes | Time | Difficulty | \n",
    "|---------|------|------------|\n",
    "|resize images to be 128 by 128 and convert it to tensor|10 mins|1|\n",
    "|Create dataloaders and setting the batch size to 32. Shuffle training data but left testing data unshuffle|10 mins|1|\n",
    "|Initialise the model with 2 conv layers and 1 pooling in between them. After running the training with 15 epocs , the loss is 0.0035 but the accuracy is 51.9%|30 mins|3|\n",
    "|Try changing the number of layer but was met with error for number of output and input were different|1 hour|6|\n",
    "|use 3 conv layer and pooling after every conv layer but accuracy was lower. I think is because it has too many pooling layer|30 mins|3|\n",
    "|Try different epocs value but loss reduce less at around 15 epocs|20 mins|2|\n",
    "|Change the learning rate to 0.0005 instead of 0.001 but similar result|5 mins|1|\n",
    "|Add another conv layer to make it to 3 layer and do pooling at the end of conv layer instead of in between and increase the accuracy to 52.2%|30 mins|3|\n",
    "|The loss is very low , it could be the neural network was memorizing the training set so include drop out to drop a neuron for better generalisation. The loss is now 0.3859 but accuracy increase to 55%|45 mins|5|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ef2cf4-2733-4461-8689-f6f473d3cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "673d82ed-ad95-4795-89f2-c9b7a275370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "89c2ae76-56d6-41a6-899a-111cd6da3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "train_dataset = ImageFolder(root=\"fruit_data/train\", transform=transform)\n",
    "\n",
    "# Load validation dataset\n",
    "val_dataset = ImageFolder(root=\"fruit_data/test\", transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "61600bae-6a10-4e55-9927-f41656133a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple', 'Banana', 'avocado', 'cherry', 'kiwi', 'mango', 'orange', 'pinenapple', 'strawberries', 'watermelon']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.classes)  # Check labels\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75eab1be-f0b5-411e-b1e2-433b50cefd2d",
   "metadata": {},
   "source": [
    "class FruitCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):  # 10 classes of label\n",
    "        super(FruitCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1c9f301a-549b-4fe5-b624-12e4ace09dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):  \n",
    "        super(FruitCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Pooling Layer \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Fully Connected Layers \n",
    "        self.fc1 = nn.Sequential(nn.Linear(128 * 16 * 16, 256), nn.ReLU(), nn.Dropout(0.5))\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)  # Final output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 32, 64, 64) → (B, 32, 32, 32)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 64, 32, 32) → (B, 64, 16, 16)\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # (B, 128, 16, 16) → (B, 128, 8, 8)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten (B, 128*8*8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e63cb66e-6a9f-42f4-b86b-2ad71e7bb4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = FruitCNN(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6a0ea6ea-ee31-4c00-a75e-4124719c71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # For classification tasks\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ff785a23-d785-42ec-87c8-63f7f7046d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 1.9787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], Loss: 1.5860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], Loss: 1.4432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], Loss: 1.3581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], Loss: 1.1981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15], Loss: 1.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], Loss: 1.0319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15], Loss: 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], Loss: 0.8144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], Loss: 0.7014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15], Loss: 0.5907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], Loss: 0.4919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], Loss: 0.4201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], Loss: 0.3389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Loss: 0.2640\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Show progress bar\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for images, labels in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b6ba59e7-5a6d-407c-9519-bb4f6dd8cbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 54.44%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "71aab273-c758-49de-adf5-efc7e4787cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76404494 0.10476191 0.04716981 0.72380954 0.6952381  0.31428573\n",
      " 0.82474226 0.83809525 0.61165047 0.5809524 ]\n"
     ]
    }
   ],
   "source": [
    "correct = torch.zeros(10).to(device)\n",
    "total = torch.zeros(10).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        for label in range(10):\n",
    "            correct[label] += (preds[labels == label] == label).sum()\n",
    "            total[label] += (labels == label).sum()\n",
    "\n",
    "accuracy_per_class = correct / total\n",
    "print(accuracy_per_class.cpu().numpy())  # See per-class accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f6f5c-cdf8-4fb3-a3b1-d595a843804b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
